{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Problems are Composed of Several Small Data Problems\n",
    "\n",
    "[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](http://slack.fugue.ai)\n",
    "\n",
    "Partitioning is one of the fundamental concepts in distributed computing. In the local setting, all of the data fits in one machine. In the distributed setting, the data is spread across multiple machines, and often has to be moved around to perform an operation (which is called a shuffle). There is a subtle but importance difference.\n",
    "\n",
    "Fugue abstracts the partitioning to make it easy so that users have to worry about it less. Still, it's important to know this concept to leverage distributed computing effectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Scenarios\n",
    "\n",
    "In the previous section, we ended with a scikit-learn pipeline that was applied for each group of data. When you data a big dataset, there is a high chance that there are logical grouping that can serve as the basis of parallelization. Can we tackle the problem per user? per region? per item in a store? It's very common to see that machine learning models for one region may not translate well for another region. It's also very common to have data stored in the same column that may be different units (currencies).\n",
    "\n",
    "Once we break up big data into a small problems, we can focus on the logic for one group of data, iterate quickly, and then scale with Fugue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Partitioning Example\n",
    "\n",
    "In the DataFrame below, we want to take the difference of the value per day. Because there are three different ids, we want to make sure that we don’t get the difference across ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id  value\n",
       "0  2021-01-01  A      3\n",
       "1  2021-01-02  A      4\n",
       "2  2021-01-03  A      2\n",
       "3  2021-01-01  B      1\n",
       "4  2021-01-02  B      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.DataFrame({\"date\":[\"2021-01-01\", \"2021-01-02\", \"2021-01-03\"] * 3,\n",
    "                   \"id\": ([\"A\"]*3 + [\"B\"]*3 + [\"C\"]*3),\n",
    "                   \"value\": [3, 4, 2, 1, 2, 5, 3, 2, 3]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a function that takes in a pd.DataFrame and outputs a pd.DataFrame. This will allow us to bring the logic to Spark and Dask as we’ve seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.assign(diff=df['value'].diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we use the function directly seen below, we notice that the first row of B has a value instead of a NaN. This is wrong since the function used the value from A to calculate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id  value  diff\n",
       "0  2021-01-01  A      3   NaN\n",
       "1  2021-01-02  A      4   1.0\n",
       "2  2021-01-03  A      2  -2.0\n",
       "3  2021-01-01  B      1  -1.0\n",
       "4  2021-01-02  B      2   1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fugue import transform\n",
    "transform(df.copy(), \n",
    "          diff, \n",
    "          schema=\"*, diff:int\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is solved by passing the partitions to Fugue’s transform(). We now see the correct output of NaN for the first value of B seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id  value  diff\n",
       "0  2021-01-01  A      3   NaN\n",
       "1  2021-01-02  A      4   1.0\n",
       "2  2021-01-03  A      2  -2.0\n",
       "3  2021-01-01  B      1   NaN\n",
       "4  2021-01-02  B      2   1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(df.copy(), \n",
    "          diff, \n",
    "          schema=\"*, diff:int\",\n",
    "          partition={\"by\": \"id\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presort\n",
    "\n",
    "We mentioned previous that Spark does not guarantee order. For operations like diff above, we need to make sure the records are ordered by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id  value  diff\n",
       "0  2021-01-01  A      3   NaN\n",
       "1  2021-01-02  A      4   1.0\n",
       "2  2021-01-03  A      2  -2.0\n",
       "3  2021-01-01  B      1   NaN\n",
       "4  2021-01-02  B      2   1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(df.copy(), \n",
    "          diff, \n",
    "          schema=\"*, diff:int\",\n",
    "          partition={\"by\": \"id\", \"presort\": \"date asc\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference of groupby-apply and partition-transform is that the partition-transform semantic is much more scalable because it accounts for the physical location of the data. In addition to the column, we can also define a partitioning strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning Strategies\n",
    "\n",
    "Fugue has some partitioning strategies available off the shelf. There is also a new one not in this diagram called `coarse`.\n",
    "\n",
    "![img](https://miro.medium.com/v2/resize:fit:1400/0*5_v4ziLbsZztCavk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how to use a partitioning strategy alongside the `by` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id  value  diff\n",
       "0  2021-01-01  A      3   NaN\n",
       "1  2021-01-02  A      4   1.0\n",
       "2  2021-01-03  A      2  -2.0\n",
       "3  2021-01-01  B      1   NaN\n",
       "4  2021-01-02  B      2   1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform(df.copy(), \n",
    "          diff, \n",
    "          schema=\"*, diff:int\",\n",
    "          partition={\"by\": \"id\", \"presort\": \"date asc\",\"algo\": \"hash\"}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling to Big Data\n",
    "\n",
    "Again, if the `transform()` code works on the local engine, it will also work on Spark, Dask, and Ray by just passing the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/25 10:45:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "+----------+---+-----+----+\n",
      "|      date| id|value|diff|\n",
      "+----------+---+-----+----+\n",
      "|2021-01-01|  B|    1|null|\n",
      "|2021-01-02|  B|    2|   1|\n",
      "|2021-01-03|  B|    5|   3|\n",
      "|2021-01-01|  C|    3|null|\n",
      "|2021-01-02|  C|    2|  -1|\n",
      "|2021-01-03|  C|    3|   1|\n",
      "|2021-01-01|  A|    3|null|\n",
      "|2021-01-02|  A|    4|   1|\n",
      "|2021-01-03|  A|    2|  -2|\n",
      "+----------+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "transform(df.copy(), \n",
    "          diff, \n",
    "          schema=\"*, diff:int\",\n",
    "          partition={\"by\": \"id\", \"presort\": \"date asc\",\"algo\": \"hash\"},\n",
    "          engine=spark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even Partitions\n",
    "\n",
    "Even partitioning is interesting because it's a perfect fit for small data, but large compute. For example, we have 4 machines and 4 models to run, we can assign 1 model per machine. This is not trivial and takes a lot of extra code on the Fugue side.\n",
    "\n",
    "In the example below, we run AutoARIMA models for each timeseries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fugue/lib/python3.8/site-packages/statsforecast/core.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>1.151166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2.073378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>3.046169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>4.093130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds         y\n",
       "0          0 2000-01-01  0.000057\n",
       "1          0 2000-01-02  1.151166\n",
       "2          0 2000-01-03  2.073378\n",
       "3          0 2000-01-04  3.046169\n",
       "4          0 2000-01-05  4.093130"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsforecast.utils import generate_series\n",
    "from statsforecast.models import AutoARIMA\n",
    "from statsforecast.core import StatsForecast\n",
    "\n",
    "series = generate_series(n_series=4, seed=1).reset_index()\n",
    "series['unique_id'] = series['unique_id'].astype(int)\n",
    "\n",
    "def run_forecast(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    model = StatsForecast(df=series,\n",
    "                        models=[AutoARIMA()], \n",
    "                        freq='D', \n",
    "                        n_jobs=1)\n",
    "    return model.forecast(7).reset_index()\n",
    "\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+\n",
      "|unique_id|        ds| AutoARIMA|\n",
      "+---------+----------+----------+\n",
      "|        0|2000-03-28| 1.8282341|\n",
      "|        0|2000-03-29| 1.4334649|\n",
      "|        0|2000-03-30|  1.123938|\n",
      "|        0|2000-03-31|0.88124686|\n",
      "|        0|2000-04-01|0.69095993|\n",
      "|        0|2000-04-02|0.54176146|\n",
      "|        0|2000-04-03|0.42477933|\n",
      "|        1|2000-10-12|0.99109846|\n",
      "|        1|2000-10-13| 1.0415428|\n",
      "|        1|2000-10-14|-1.8498392|\n",
      "|        1|2000-10-15|       0.0|\n",
      "|        1|2000-10-16|       0.0|\n",
      "|        1|2000-10-17|       0.0|\n",
      "|        1|2000-10-18|       0.0|\n",
      "+---------+----------+----------+\n",
      "only showing top 14 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forecasts = transform(series, \n",
    "                      run_forecast, \n",
    "                      schema=\"unique_id:int, ds:date, AutoARIMA:float\", \n",
    "                      partition={\"by\": \"unique_id\", \"presort\": \"ds asc\", \"algo\": \"even\"},\n",
    "                      engine=spark)\n",
    "forecasts.show(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced - Running Compute Intensive Jobs\n",
    "\n",
    "Taking this one step further, we can even create a DataFrame of jobs. `pickle` brings the data to a binary representation. We can create a DataFrame consisting of pickled data easily with Fugue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>data</th>\n",
       "      <th>fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'\\x80\\x05\\x95\\x1b\\x0c\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x80\\x05\\x95\\xaf\\x1e\\x00\\x00\\x00\\x00\\x00\\x00...</td>\n",
       "      <td>b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b'\\x80\\x05\\x95\\xc7-\\x00\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "      <td>b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>b'\\x80\\x05\\x95c\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "      <td>b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id                                               data  \\\n",
       "0          0  b'\\x80\\x05\\x95\\x1b\\x0c\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "1          1  b'\\x80\\x05\\x95\\xaf\\x1e\\x00\\x00\\x00\\x00\\x00\\x00...   \n",
       "2          2  b'\\x80\\x05\\x95\\xc7-\\x00\\x00\\x00\\x00\\x00\\x00\\x8...   \n",
       "3          3  b'\\x80\\x05\\x95c\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x8...   \n",
       "\n",
       "                                                  fn  \n",
       "0  b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...  \n",
       "1  b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...  \n",
       "2  b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...  \n",
       "3  b'\\x80\\x05\\x95\\xea^\\x00\\x00\\x00\\x00\\x00\\x00\\x8...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cloudpickle\n",
    "from typing import List, Iterable, Dict, Any\n",
    "\n",
    "def serialize(df: pd.DataFrame) -> Iterable[Dict[str,Any]]:\n",
    "    yield {\"unique_id\": df.iloc[0]['unique_id'],\n",
    "           \"data\": cloudpickle.dumps(df), \n",
    "           \"fn\": cloudpickle.dumps(run_forecast)}\n",
    "\n",
    "serialized = transform(series, serialize, schema=\"unique_id:int,data:binary,fn:binary\", partition={\"by\": \"unique_id\"})\n",
    "serialized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function run_forecast at 0x7fc4b90ff1f0>\n",
      "<function run_forecast at 0x7f9d30be8940>\n",
      "<function run_forecast at 0x7fd2713525e0>\n",
      "<function run_forecast at 0x7f9d30be8700>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>AutoARIMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-03-28</td>\n",
       "      <td>1.828234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-03-29</td>\n",
       "      <td>1.433465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>1.123938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>0.881247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>0.690960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id         ds  AutoARIMA\n",
       "0          0 2000-03-28   1.828234\n",
       "1          0 2000-03-29   1.433465\n",
       "2          0 2000-03-30   1.123938\n",
       "3          0 2000-03-31   0.881247\n",
       "4          0 2000-04-01   0.690960"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_job(df: List[Dict[str,Any]]) -> pd.DataFrame:\n",
    "    row = df[0]\n",
    "    series = cloudpickle.loads(row['data'])\n",
    "    forecaster = cloudpickle.loads(row['fn'])\n",
    "    result = forecaster(series)\n",
    "    return result\n",
    "\n",
    "results = transform(serialized, \n",
    "                    run_job, \n",
    "                    schema=\"unique_id:int,ds:date,AutoARIMA:float\", \n",
    "                    partition={\"by\": \"unique_id\", \"how\": \"even\"},\n",
    "                    engine=spark)\n",
    "results.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practice\n",
    "\n",
    "Something to be aware of is 2-stage parallelism. Note that we set the `n_jobs` to 1 in the previous timeseries forecasting function. This is because having multiple parallel jobs can cause resource contention and actually cause jobs to slow down.\n",
    "\n",
    "Second, it's much better to miminize data transfer by passing a path to a file rather than passing the data itself. The goal is for the worker to load the file directly.\n",
    "\n",
    "Third, it's more stable to use `cloudpickle` over `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Validation by Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we use the open-source [Pandera](https://github.com/unionai-oss/pandera) library for data validation. We have two different regions and want to validate each separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'state': ['FL','FL','FL','CA','CA','CA'],\n",
    "        'city': [\n",
    "            'Orlando', 'Miami', 'Tampa', 'San Francisco', 'Los Angeles', 'San Diego'\n",
    "        ],\n",
    "        'price': [8, 12, 10, 16, 20, 18],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandera import Column, DataFrameSchema, Check\n",
    "\n",
    "price_check_FL = DataFrameSchema({\n",
    "    \"price\": Column(int, Check.in_range(min_value=7,max_value=13)),\n",
    "})\n",
    "\n",
    "price_check_CA = DataFrameSchema({\n",
    "    \"price\": Column(int, Check.in_range(min_value=15,max_value=21)),\n",
    "})\n",
    "\n",
    "price_checks = {'CA': price_check_CA, 'FL': price_check_FL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These checks can be applied as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state           city  price\n",
       "3    CA  San Francisco     16\n",
       "4    CA    Los Angeles     20\n",
       "5    CA      San Diego     18"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_check_CA.validate(data.loc[data['state'] == 'CA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But of course it will fail when applied to FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema Column(name=price, type=DataType(int64))> failed element-wise validator 0:\n",
      "<Check in_range: in_range(15, 21)>\n",
      "failure cases:\n",
      "   index  failure_case\n",
      "0      0             8\n",
      "1      1            12\n",
      "2      2            10\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    price_check_CA.validate(data.loc[data['state'] == 'FL'])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to we run the appropriate validator for each region in parallel with Spark?\n",
    "\n",
    "1. Create a `price_validation` function\n",
    "2. Get the state of the partition\n",
    "3. Pull the appropriate validator\n",
    "4. Run the validation\n",
    "5. Parallelize with the `transform()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this section we learned about partitions. This is an example of how sticking to a mindset can limit full utilization of the distributed system. Pandas doesn't have an innate concept of partitioning.\n",
    "\n",
    "Fugue's partitioning also allows users to focus on the logic of one partition. When ready to scale, we just run the logic across all partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fugue')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fcd6e71927f6b3e5f4fa4280b4e8e6a66aa8d4365bb61cf7ef4017620fc09b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
