{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fugue Roadmap (10 mins)\n",
    "\n",
    "Fugue has already done significant work on the Python side by scaling Pandas, SQL, and Python code to Spark, Dask, and Ray. The future is more about integrating with other open-source tools and backends.\n",
    "\n",
    "[![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](http://slack.fugue.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=!mamba install -y openjdk\n",
    "_=!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Source Integrations\n",
    "\n",
    "* [whylogs](https://github.com/whylabs/whylogs) - data profiling\n",
    "* [pycaret](https://github.com/pycaret/pycaret) - low code machine learning\n",
    "* [statsforecast](https://github.com/Nixtla/statsforecast/) - lightning fast timeseries models\n",
    "* [ipyvizzu](https://github.com/vizzuhq/ipyvizzu-story) - interactive data stories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polars Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "data = {\"id\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\"],\n",
    "        \"number\": [10, 20, 30, 15, 25, 35, 20, 30, 40]}\n",
    "df = pl.DataFrame(data)\n",
    "\n",
    "# schema: *, diff:float\n",
    "def diff(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.with_columns(pl.col(\"number\").diff().alias(\"diff\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DuckDB + Polars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue_jupyter import setup\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id:str</th>\n",
       "      <th>number:long</th>\n",
       "      <th>diff:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>25</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>40</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<font size=\"-1\">PandasDataFrame: id:str,number:long,diff:float</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fsql duckdb\n",
    "SELECT *\n",
    "  FROM df\n",
    " WHERE id IN ('B', 'C')\n",
    "\n",
    "TRANSFORM PREPARTITION BY id USING diff \n",
    "PRINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Runing Distributedly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/26 07:58:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/26 07:58:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>number</th><th>diff</th></tr><tr><td>str</td><td>i64</td><td>f32</td></tr></thead><tbody><tr><td>&quot;B&quot;</td><td>15</td><td>null</td></tr><tr><td>&quot;B&quot;</td><td>25</td><td>10.0</td></tr><tr><td>&quot;B&quot;</td><td>35</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>20</td><td>null</td></tr><tr><td>&quot;C&quot;</td><td>30</td><td>10.0</td></tr><tr><td>&quot;C&quot;</td><td>40</td><td>10.0</td></tr><tr><td>&quot;A&quot;</td><td>10</td><td>null</td></tr><tr><td>&quot;A&quot;</td><td>20</td><td>10.0</td></tr><tr><td>&quot;A&quot;</td><td>30</td><td>10.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 3)\n",
       "┌─────┬────────┬──────┐\n",
       "│ id  ┆ number ┆ diff │\n",
       "│ --- ┆ ---    ┆ ---  │\n",
       "│ str ┆ i64    ┆ f32  │\n",
       "╞═════╪════════╪══════╡\n",
       "│ B   ┆ 15     ┆ null │\n",
       "│ B   ┆ 25     ┆ 10.0 │\n",
       "│ B   ┆ 35     ┆ 10.0 │\n",
       "│ C   ┆ 20     ┆ null │\n",
       "│ …   ┆ …      ┆ …    │\n",
       "│ C   ┆ 40     ┆ 10.0 │\n",
       "│ A   ┆ 10     ┆ null │\n",
       "│ A   ┆ 20     ┆ 10.0 │\n",
       "│ A   ┆ 30     ┆ 10.0 │\n",
       "└─────┴────────┴──────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fugue.api as fa\n",
    "from fugue.api import transform\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Output is Spark DataFrame\n",
    "res = fa.transform(df, diff, partition={\"by\": \"id\"}, engine=spark)\n",
    "\n",
    "pl.from_arrow(fa.as_arrow(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery Integration\n",
    "\n",
    "Our SQL has been limited to SQL on top of Python DataFrames until recently. We want to facilitate the synergy of using data warehouses with distributed computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "from typing import List, Any\n",
    "\n",
    "# schema: *\n",
    "def median(df:pd.DataFrame) -> List[List[Any]]:\n",
    "    return [[df.state.iloc[0], df.number.median()]]\n",
    "\n",
    "fa.transform(\n",
    "    (\"bq\", \"\"\"SELECT state, number\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_2013` TABLESAMPLE SYSTEM (1 PERCENT)\"\"\"),\n",
    "    median,\n",
    "    partition=\"state\",\n",
    "    engine=\"dask\"\n",
    ").compute().head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Plans\n",
    "\n",
    "* Snowflake Integration - Utilize Snowflake and Databricks together\n",
    "* Use DuckDB for local testing before bringing to data warehouses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('fugue')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fcd6e71927f6b3e5f4fa4280b4e8e6a66aa8d4365bb61cf7ef4017620fc09b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
